{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yBnmbg-jdztQ"
   },
   "source": [
    "# HW2 Spam Classification with LSTM model\n",
    "\n",
    "The deadline is **2 pm Feb 25, 2021**.   \n",
    "You should submit a `.ipynb` file with your solutions to NYU Brightspace.\n",
    "\n",
    "---\n",
    "\n",
    "In this homework, we will reuse the spam prediction dataset used in HW1.\n",
    "We will use a word-level BiLSTM sentence encoder to encode the sentence and a neural network classifier.\n",
    "\n",
    "For reference, you may read [this paper](https://arxiv.org/abs/1705.02364).\n",
    "\n",
    "Content of this HW is related with Lab 3 Deep Learning.\n",
    "\n",
    "## Points distribution\n",
    "\n",
    "1. code `spam_collate_func`: 25 pts\n",
    "2. code `LSTMClassifier.init`: 25 pts\n",
    "3. code `LSTMClassifier.forward`: 20 pts\n",
    "4. code `evaluate`: 10 pts\n",
    "5. code for training loop: 10 pts\n",
    "6. Question: `Why do we want to use early stopping?`: 10 pts\n",
    "\n",
    "How we grade the code: \n",
    "- full points if code works and the underlying logic is correct;\n",
    "- half points if code works but the underlying logic is incorrect;\n",
    "- zero points if code does not work.\n",
    "\n",
    "TLDR: **make sure your code works, i.e. no errors are being produced when you call the function (not when you defined it in the cell!).**\n",
    "\n",
    "How we grade the open question:\n",
    "* full points if your answer follows lecture materials.\n",
    "* zero points if your answer contradicts lecture materials."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TKJv-b6RewJn"
   },
   "source": [
    "# Data Loading\n",
    "First, reuse the code from HW1 to download and read the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 326
    },
    "executionInfo": {
     "elapsed": 2255,
     "status": "ok",
     "timestamp": 1581547426786,
     "user": {
      "displayName": "Phu Mon Htut",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBI1zWVSj8KF1s1_jeDXNGym9w1t-flSjNjJ-SN=s64",
      "userId": "00211106001036927242"
     },
     "user_tz": 300
    },
    "id": "QoiahW1_fZ6p",
    "outputId": "fd71da05-026d-4b2f-b8ce-15855277dfc5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-02-25 13:25:29--  https://docs.google.com/uc?export=download&id=1OVRo37agn02mc6yp5p6-wtJ8Hyb-YMXR\n",
      "Resolving docs.google.com (docs.google.com)... 216.58.200.174\n",
      "Connecting to docs.google.com (docs.google.com)|216.58.200.174|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
      "Location: https://doc-14-04-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/b55qcmfsdoagrc7d7kslprmpkb8qmlvg/1614239700000/08752484438609855375/*/1OVRo37agn02mc6yp5p6-wtJ8Hyb-YMXR?e=download [following]\n",
      "Warning: wildcards not supported in HTTP.\n",
      "--2021-02-25 13:25:30--  https://doc-14-04-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/b55qcmfsdoagrc7d7kslprmpkb8qmlvg/1614239700000/08752484438609855375/*/1OVRo37agn02mc6yp5p6-wtJ8Hyb-YMXR?e=download\n",
      "Resolving doc-14-04-docs.googleusercontent.com (doc-14-04-docs.googleusercontent.com)... 172.217.31.1\n",
      "Connecting to doc-14-04-docs.googleusercontent.com (doc-14-04-docs.googleusercontent.com)|172.217.31.1|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 503663 (492K) [text/csv]\n",
      "Saving to: ‘spam.csv’\n",
      "\n",
      "spam.csv            100%[===================>] 491.86K  2.61MB/s    in 0.2s    \n",
      "\n",
      "2021-02-25 13:25:31 (2.61 MB/s) - ‘spam.csv’ saved [503663/503663]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget 'https://docs.google.com/uc?export=download&id=1OVRo37agn02mc6yp5p6-wtJ8Hyb-YMXR' -O spam.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7.1\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "executionInfo": {
     "elapsed": 2243,
     "status": "ok",
     "timestamp": 1581547426788,
     "user": {
      "displayName": "Phu Mon Htut",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBI1zWVSj8KF1s1_jeDXNGym9w1t-flSjNjJ-SN=s64",
      "userId": "00211106001036927242"
     },
     "user_tz": 300
    },
    "id": "I52OxyBgfi_j",
    "outputId": "4039e309-a36c-479d-8eee-afcc1b2b414a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   v1                                                 v2\n",
       "0   0  Go until jurong point, crazy.. Available only ...\n",
       "1   0                      Ok lar... Joking wif u oni...\n",
       "2   1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   0  U dun say so early hor... U c already then say...\n",
       "4   0  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(\"spam.csv\", usecols=[\"v1\", \"v2\"], encoding='latin-1')\n",
    "# 1 - spam, 0 - ham\n",
    "df.v1 = (df.v1 == \"spam\").astype(\"int\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pCihb3oogn27"
   },
   "source": [
    "We will split the data into train, val, and test sets.  \n",
    "`train_texts`, `val_texts`, and `test_texts` should contain a list of text examples in the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "executionInfo": {
     "elapsed": 2233,
     "status": "ok",
     "timestamp": 1581547426789,
     "user": {
      "displayName": "Phu Mon Htut",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBI1zWVSj8KF1s1_jeDXNGym9w1t-flSjNjJ-SN=s64",
      "userId": "00211106001036927242"
     },
     "user_tz": 300
    },
    "id": "0H78E3FLgEA2",
    "outputId": "d2744479-c9f2-4c6c-d321-3dc78f003e1d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of initial data: 5572\n",
      "Train size: 3902\n",
      "Val size: 835\n",
      "Test size: 835\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 0.15 for val, 0.15 for test, 0.7 for train\n",
    "val_size = int(df.shape[0] * 0.15)\n",
    "test_size = int(df.shape[0] * 0.15)\n",
    "\n",
    "# Shuffle the data\n",
    "df = df.sample(frac=1)\n",
    "# Split df to test/val/train\n",
    "test_df = df[:test_size]\n",
    "val_df = df[test_size:test_size+val_size]\n",
    "train_df = df[test_size+val_size:]\n",
    "\n",
    "\n",
    "train_texts, train_labels = list(train_df.v2), list(train_df.v1)\n",
    "val_texts, val_labels     = list(val_df.v2), list(val_df.v1)\n",
    "test_texts, test_labels   = list(test_df.v2), list(test_df.v1)\n",
    "\n",
    "\n",
    "# Check that idces do not overlap\n",
    "assert set(train_df.index).intersection(set(val_df.index)) == set({})\n",
    "assert set(test_df.index).intersection(set(train_df.index)) == set({})\n",
    "assert set(val_df.index).intersection(set(test_df.index)) == set({})\n",
    "# Check that all idces are present\n",
    "assert df.shape[0] == len(train_labels) + len(val_labels) + len(test_labels)\n",
    "1\n",
    "# Sizes\n",
    "print(\n",
    "    f\"Size of initial data: {df.shape[0]}\\n\"\n",
    "    f\"Train size: {len(train_labels)}\\n\"\n",
    "    f\"Val size: {len(val_labels)}\\n\"\n",
    "    f\"Test size: {len(test_labels)}\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 207
    },
    "executionInfo": {
     "elapsed": 2195,
     "status": "ok",
     "timestamp": 1581547426789,
     "user": {
      "displayName": "Phu Mon Htut",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBI1zWVSj8KF1s1_jeDXNGym9w1t-flSjNjJ-SN=s64",
      "userId": "00211106001036927242"
     },
     "user_tz": 300
    },
    "id": "FX8D130ngVxu",
    "outputId": "32373f62-748e-4ae0-99df-a24e527947fd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['We are at grandmas. Oh dear, u still ill? I felt Shit this morning but i think i am just hungover! Another night then. We leave on sat.',\n",
       " \"Oh dang! I didn't mean o send that to you! Lol!\",\n",
       " 'Do u konw waht is rael FRIENDSHIP Im gving yuo an exmpel: Jsut ese tihs msg.. Evrey splleing of tihs msg is wrnog.. Bt sitll yuo can raed it wihtuot ayn mitsake.. GOODNIGHT &amp; HAVE A NICE SLEEP..SWEET DREAMS..',\n",
       " \"It could work, we'll reach a consensus at the next meeting\",\n",
       " \"Tell me they're female :V how're you throwing in? We're deciding what all to get now\",\n",
       " \"The world's most happiest frnds never have the same characters... Dey just have the best understanding of their differences...\",\n",
       " 'You are a very very very very bad girl. Or lady.',\n",
       " 'Hmmm.still we dont have opener?',\n",
       " 'Free msg: Single? Find a partner in your area! 1000s of real people are waiting to chat now!Send CHAT to 62220Cncl send STOPCS 08717890890å£1.50 per msg',\n",
       " 'Its a valentine game. . . Send dis msg to all ur friends. .. If 5 answers r d same then someone really loves u. Ques- which colour suits me the best?rply me']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_texts[:10] # Just checking the examples in train_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Sm_iuR_hJp2"
   },
   "source": [
    "# Download and Load GloVe Embeddings\n",
    "We will use GloVe embedding parameters to initialize our layer of word representations / embedding layer.\n",
    "Let's download and load glove.\n",
    "\n",
    "\n",
    "This is related Lab 3 Deep Learning, please watch the recording and check the notebook for details.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14355,
     "status": "ok",
     "timestamp": 1612883470632,
     "user": {
      "displayName": "Ilia Kulikov",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi1RtZsBHzWWvp1QeWCiWcKS_m-npZXTXlHMC65=s64",
      "userId": "03884324343674643556"
     },
     "user_tz": 300
    },
    "id": "HRCcCtcSjEPR",
    "outputId": "1bdd9bee-935b-4412-dd2b-b2def6f76bf9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-02-25 13:25:40--  https://docs.google.com/uc?id=1KMJTagaVD9hFHXFTPtNk0u2JjvNlyCAu\n",
      "Resolving docs.google.com (docs.google.com)... 216.58.200.174\n",
      "Connecting to docs.google.com (docs.google.com)|216.58.200.174|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
      "Location: https://doc-0k-0g-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/8cp2tgoh5b5pcfru6spr1p3m7df5fsot/1614239700000/14514704803973256873/*/1KMJTagaVD9hFHXFTPtNk0u2JjvNlyCAu [following]\n",
      "Warning: wildcards not supported in HTTP.\n",
      "--2021-02-25 13:25:45--  https://doc-0k-0g-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/8cp2tgoh5b5pcfru6spr1p3m7df5fsot/1614239700000/14514704803973256873/*/1KMJTagaVD9hFHXFTPtNk0u2JjvNlyCAu\n",
      "Resolving doc-0k-0g-docs.googleusercontent.com (doc-0k-0g-docs.googleusercontent.com)... 216.58.200.161\n",
      "Connecting to doc-0k-0g-docs.googleusercontent.com (doc-0k-0g-docs.googleusercontent.com)|216.58.200.161|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: unspecified [audio/audible]\n",
      "Saving to: ‘glove_split.aa’\n",
      "\n",
      "glove_split.aa          [              <=>   ]  50.00M  7.15MB/s    in 7.0s    \n",
      "\n",
      "2021-02-25 13:25:53 (7.12 MB/s) - ‘glove_split.aa’ saved [52428800]\n",
      "\n",
      "--2021-02-25 13:25:53--  https://docs.google.com/uc?id=1LF2yD2jToXriyD-lsYA5hj03f7J3ZKaY\n",
      "Resolving docs.google.com (docs.google.com)... 216.58.200.174\n",
      "Connecting to docs.google.com (docs.google.com)|216.58.200.174|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
      "Location: https://doc-08-0g-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/qpdccqvreqo77q5oi1grkdd23dpjrd25/1614239700000/14514704803973256873/*/1LF2yD2jToXriyD-lsYA5hj03f7J3ZKaY [following]\n",
      "Warning: wildcards not supported in HTTP.\n",
      "--2021-02-25 13:25:56--  https://doc-08-0g-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/qpdccqvreqo77q5oi1grkdd23dpjrd25/1614239700000/14514704803973256873/*/1LF2yD2jToXriyD-lsYA5hj03f7J3ZKaY\n",
      "Resolving doc-08-0g-docs.googleusercontent.com (doc-08-0g-docs.googleusercontent.com)... 216.58.221.33\n",
      "Connecting to doc-08-0g-docs.googleusercontent.com (doc-08-0g-docs.googleusercontent.com)|216.58.221.33|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: unspecified [application/octet-stream]\n",
      "Saving to: ‘glove_split.ab’\n",
      "\n",
      "glove_split.ab          [                 <=>]  50.00M  9.19MB/s    in 5.4s    \n",
      "\n",
      "2021-02-25 13:26:03 (9.19 MB/s) - ‘glove_split.ab’ saved [52428800]\n",
      "\n",
      "--2021-02-25 13:26:03--  https://docs.google.com/uc?id=1N1xnxkRyM5Gar7sv4d41alyTL92Iip3f\n",
      "Resolving docs.google.com (docs.google.com)... 216.58.200.174\n",
      "Connecting to docs.google.com (docs.google.com)|216.58.200.174|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
      "Location: https://doc-04-0g-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/4pi94ri70vblusaa5420h4iui6bpelvb/1614239700000/14514704803973256873/*/1N1xnxkRyM5Gar7sv4d41alyTL92Iip3f [following]\n",
      "Warning: wildcards not supported in HTTP.\n",
      "--2021-02-25 13:26:05--  https://doc-04-0g-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/4pi94ri70vblusaa5420h4iui6bpelvb/1614239700000/14514704803973256873/*/1N1xnxkRyM5Gar7sv4d41alyTL92Iip3f\n",
      "Resolving doc-04-0g-docs.googleusercontent.com (doc-04-0g-docs.googleusercontent.com)... 172.217.31.1\n",
      "Connecting to doc-04-0g-docs.googleusercontent.com (doc-04-0g-docs.googleusercontent.com)|172.217.31.1|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: unspecified [application/octet-stream]\n",
      "Saving to: ‘glove_split.ac’\n",
      "\n",
      "glove_split.ac          [          <=>       ]  23.49M  7.38MB/s    in 3.2s    \n",
      "\n",
      "2021-02-25 13:26:09 (7.38 MB/s) - ‘glove_split.ac’ saved [24629432]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#@title Download GloVe word embeddings\n",
    "\n",
    "# === Download GloVe word embeddings\n",
    "# !wget http://nlp.stanford.edu/data/glove.6B.zip\n",
    "\n",
    "# === Unzip word embeddings and use only the top 50000 word embeddings for speed\n",
    "# !unzip glove.6B.zip\n",
    "# !head -n 50000 glove.6B.300d.txt > glove.6B.300d__50k.txt\n",
    "\n",
    "# === Download Preprocessed version\n",
    "!wget https://docs.google.com/uc?id=1KMJTagaVD9hFHXFTPtNk0u2JjvNlyCAu -O glove_split.aa\n",
    "!wget https://docs.google.com/uc?id=1LF2yD2jToXriyD-lsYA5hj03f7J3ZKaY -O glove_split.ab\n",
    "!wget https://docs.google.com/uc?id=1N1xnxkRyM5Gar7sv4d41alyTL92Iip3f -O glove_split.ac\n",
    "!cat glove_split.?? > 'glove.6B.300d__50k.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4AfN4rYTOmCD"
   },
   "source": [
    "## Load GloVe Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "TSF0C4jHjnSz"
   },
   "outputs": [],
   "source": [
    "def load_glove(glove_path, embedding_dim):\n",
    "    with open(glove_path) as f:\n",
    "        token_ls = [PAD_TOKEN, UNK_TOKEN]\n",
    "        embedding_ls = [np.zeros(embedding_dim), np.random.rand(embedding_dim)]\n",
    "        for line in f:\n",
    "            token, raw_embedding = line.split(maxsplit=1)\n",
    "            token_ls.append(token)\n",
    "            embedding = np.array([float(x) for x in raw_embedding.split()])\n",
    "            embedding_ls.append(embedding)\n",
    "        embeddings = np.array(embedding_ls)\n",
    "    return token_ls, embeddings\n",
    "\n",
    "PAD_TOKEN = '<PAD>'\n",
    "UNK_TOKEN = '<UNK>'\n",
    "EMBEDDING_DIM=300 # dimension of Glove embeddings\n",
    "glove_path = \"glove.6B.300d__50k.txt\"\n",
    "vocab, embeddings = load_glove(glove_path, EMBEDDING_DIM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e_VZkGbgO4yA"
   },
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 292
    },
    "executionInfo": {
     "elapsed": 29400,
     "status": "ok",
     "timestamp": 1581547454050,
     "user": {
      "displayName": "Phu Mon Htut",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBI1zWVSj8KF1s1_jeDXNGym9w1t-flSjNjJ-SN=s64",
      "userId": "00211106001036927242"
     },
     "user_tz": 300
    },
    "id": "FpbnKsQeptXw",
    "outputId": "a0974576-3c36-4cfb-8b5b-31aa87d046b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sacremoses in /Users/yashbharti/opt/anaconda3/lib/python3.7/site-packages (0.0.43)\r\n",
      "Requirement already satisfied: tqdm in /Users/yashbharti/opt/anaconda3/lib/python3.7/site-packages (from sacremoses) (4.56.0)\r\n",
      "Requirement already satisfied: click in /Users/yashbharti/opt/anaconda3/lib/python3.7/site-packages (from sacremoses) (7.1.2)\r\n",
      "Requirement already satisfied: regex in /Users/yashbharti/.local/lib/python3.7/site-packages (from sacremoses) (2020.11.13)\r\n",
      "Requirement already satisfied: six in /Users/yashbharti/opt/anaconda3/lib/python3.7/site-packages (from sacremoses) (1.15.0)\r\n",
      "Requirement already satisfied: joblib in /Users/yashbharti/opt/anaconda3/lib/python3.7/site-packages (from sacremoses) (0.13.2)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install sacremoses\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import sacremoses\n",
    "from torch.utils.data import dataloader, Dataset\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Wwy3gSvO87p"
   },
   "source": [
    "# Tokenize text data.\n",
    "We will use the `tokenize` function to convert text data into sequence of indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 164,
     "referenced_widgets": [
      "48ac271c21f44353b5f8b0aec3b05f5b",
      "070548aec28842259e1ea3a56ec5f24e",
      "f10d44bc20994ac085c99ea5d2383a00",
      "6119a6e4075c4cde9bcef0773bbfa48e",
      "6f5a934da1a5478e8fc92b38c5a40584",
      "2b25f1a2a08c438da35372a5c72ee41d",
      "829223f1edb744309a9b77d3fa6818a3",
      "d6dbe87216d44c1fb48e2a2896aa0a61",
      "242d4868e48445c7a624a3c95f0d7710",
      "7a19d829556d4f9198408b1f84c3526c",
      "3b2d8b29cfde4d66a81e3bd00be18493",
      "1681f6d76be54ca09c5894ac248ee6b6",
      "95d22e0e4a8f4a31aa861ee389f284d2",
      "7116d260b3cf48138bbf372c8d7b0cf8",
      "6c5fe2fc16544a1690da6130c349ae36",
      "00c07b0a26424be38807df93cc5c0cd2",
      "783b727fd7954625ab4c5ef7dd6d4b6a",
      "cd9df6cf8cd745e7b62f5e7a53ba4ec5",
      "2f45fd22bee14ee092023d043ac17b6e",
      "d195ffd274974c2e96f5d283b2055118",
      "14f76745c455472da992886739bbdf1c",
      "9d82ca66f33f41ca92c48e04d6d0f5e3",
      "d3e79f8c059444539bf1d0436402ff12",
      "088ecefc78274663baf410c288d239df"
     ]
    },
    "executionInfo": {
     "elapsed": 31510,
     "status": "ok",
     "timestamp": 1581547456180,
     "user": {
      "displayName": "Phu Mon Htut",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBI1zWVSj8KF1s1_jeDXNGym9w1t-flSjNjJ-SN=s64",
      "userId": "00211106001036927242"
     },
     "user_tz": 300
    },
    "id": "j1aLbeOBmRyR",
    "outputId": "a5616c01-7178-4a2e-d5cf-1ff8a112ded2"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37452369ef24482487b95881b403729a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3902 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d976da4c5554edc89be3b730e2204e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/835 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2bb4cadb7a74002ab686f04bc9f31a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/835 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tokenize(data, labels, tokenizer, vocab, max_seq_length=128):\n",
    "    vocab_to_idx = {word: i for i, word in enumerate(vocab)}\n",
    "    text_data = []\n",
    "    label_data = []\n",
    "    for ex in tqdm(data):\n",
    "        tokenized = tokenizer.tokenize(ex.lower())\n",
    "        ids = [vocab_to_idx.get(token, 1) for token in tokenized]\n",
    "        text_data.append(ids)\n",
    "    return text_data, labels\n",
    "tokenizer = sacremoses.MosesTokenizer()\n",
    "train_data_indices, train_labels = tokenize(train_texts, train_labels, tokenizer, vocab)\n",
    "val_data_indices, val_labels = tokenize(val_texts, val_labels, tokenizer, vocab)\n",
    "test_data_indices, test_labels = tokenize(test_texts, test_labels, tokenizer, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "executionInfo": {
     "elapsed": 31490,
     "status": "ok",
     "timestamp": 1581547456181,
     "user": {
      "displayName": "Phu Mon Htut",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBI1zWVSj8KF1s1_jeDXNGym9w1t-flSjNjJ-SN=s64",
      "userId": "00211106001036927242"
     },
     "user_tz": 300
    },
    "id": "OEF48Bddt5kA",
    "outputId": "be094a68-7dd0-4199-83c6-da47a48ccaba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train text first 5 examples:\n",
      " [[55, 34, 24, 1, 3204, 8609, 3, 6481, 151, 3120, 190, 43, 1351, 34857, 39, 768, 36, 43, 271, 43, 915, 122, 1, 807, 172, 366, 1, 55, 893, 15, 3225, 4], [3204, 35550, 807, 43, 1, 1, 1704, 4870, 1547, 14, 6, 83, 807, 1, 807], [90, 6481, 1, 1, 16, 1, 4583, 14665, 1, 1, 31, 1, 47, 1, 47746, 1, 36523, 1, 1, 1, 5, 1, 36523, 16, 1, 1, 7671, 1, 1, 88, 40937, 22, 1, 1, 1, 1, 41255, 725, 8459, 91, 35, 9, 3084, 4296, 1, 3716, 5561, 1], [22, 96, 163, 3, 55, 1, 1024, 9, 4129, 24, 2, 184, 288], [1363, 287, 41, 1, 1634, 47, 2406, 199, 1, 83, 4560, 8, 190, 55, 1, 6072, 104, 66, 6, 171, 116]]\n",
      "\n",
      "Train labels first 5 examples:\n",
      " [0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTrain text first 5 examples:\\n\", train_data_indices[:5])\n",
    "print(\"\\nTrain labels first 5 examples:\\n\", train_labels[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    " def longest(l):\n",
    "        if not isinstance(l, list):\n",
    "            return 0\n",
    "        return max([len(l)] + [len(subl) for subl in l if isinstance(subl, list)] + [longest(subl) for subl in l])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_dlUYNvgPUXs"
   },
   "source": [
    "# Create DataLoaders (25 pts)\n",
    " Now, let's create pytorch DataLoaders for our train, val, and test data.\n",
    "\n",
    " `SpamDataset` class is based on torch [`Dataset`](https://pytorch.org/docs/1.7.0/data.html?highlight=dataset#torch.utils.data.Dataset). It has an additional parameter called `self.max_sent_length` and a `spam_collate_func`.\n",
    "\n",
    "In order to use batch processing, all the examples need to effectively be the same length. We'll do this by adding padding tokens. `spam_collate_func` is supposed to dynamically pad or trim the sentences in the batch based on `self.max_sent_length` and the length of longest sequence in the batch. \n",
    "- If `self.max_sent_length` is greater than the length of longest sequence in the batch, use `self.max_sent_length`. Otherwise, use the length of longest sequence in the batch.\n",
    "- We do this because our input sentences in the batch may be much shorter than `self.max_sent_length`.  \n",
    "\n",
    "\n",
    "Example: \n",
    "\n",
    "* PAD token id = 0\n",
    "* max_sent_length = 5\n",
    "\n",
    "input list of sequences:\n",
    "```\n",
    "inp = [\n",
    "    [1,4,5,3,5,6,7,4,4],\n",
    "    [3,5,3,2],\n",
    "    [2,5,3,5,6,7,4],\n",
    "]\n",
    "```\n",
    "then padded minibatch looks like this:\n",
    "```\n",
    "padded_input = \n",
    "    [[1,4,5,3,5],\n",
    "     [3,5,3,2,0],\n",
    "     [2,5,3,5,6]]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "-uJDfnVMxBsz"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class SpamDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Class that represents a train/validation/test dataset that's readable for PyTorch\n",
    "    Note that this class inherits torch.utils.data.Dataset\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, data_list, target_list, max_sent_length=128):\n",
    "        \"\"\"\n",
    "        @param data_list: list of data tokens \n",
    "        @param target_list: list of data targets \n",
    "\n",
    "        \"\"\"\n",
    "        self.data_list = data_list\n",
    "        self.target_list = target_list\n",
    "        self.max_sent_length = max_sent_length\n",
    "        assert (len(self.data_list) == len(self.target_list))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_list)\n",
    "        \n",
    "    def __getitem__(self, key, max_sent_length=None):\n",
    "        \"\"\"\n",
    "        Triggered when you call dataset[i]\n",
    "        \"\"\"\n",
    "        if max_sent_length is None:\n",
    "            max_sent_length = self.max_sent_length\n",
    "        token_idx = self.data_list[key][:max_sent_length]\n",
    "        label = self.target_list[key]\n",
    "        return [token_idx, label]\n",
    "    \n",
    "   \n",
    "        \n",
    "\n",
    "    def spam_collate_func(self,batch):\n",
    "        \"\"\"\n",
    "        Customized function for DataLoader that dynamically pads the batch so that all \n",
    "        data have the same length\n",
    "        \"\"\" \n",
    "        data_list = [] # store padded sequences\n",
    "        label_list = []\n",
    "        max_batch_seq_len = None # the length of longest sequence in batch\n",
    "                                 # if it is less than self.max_sent_length\n",
    "                                 # else max_batch_seq_len = self.max_sent_length\n",
    "        \n",
    "        \"\"\"\n",
    "          # Pad the sequences in your data \n",
    "          # if their length is less than max_batch_seq_len\n",
    "          # or trim the sequences that are longer than self.max_sent_length\n",
    "          # return padded data_list and label_list\n",
    "          1. TODO: Your code here \n",
    "        \"\"\"\n",
    "        \n",
    "        #Creating a list out of a batch\n",
    "        for outer in batch:\n",
    "            for inner in outer:\n",
    "                if isinstance(inner, list):\n",
    "                    data_list.append(inner)\n",
    "                elif isinstance(inner, int):\n",
    "                    label_list.append(inner)\n",
    "        \n",
    "        #Finding the maximum length in the batch\n",
    "        maxLength = max(len(x) for x in data_list)\n",
    "        if maxLength < self.max_sent_length:\n",
    "            max_batch_seq_len = maxLength\n",
    "        else:\n",
    "            max_batch_seq_len = self.max_sent_length\n",
    "        \n",
    "        \n",
    "        # Slicing or padding\n",
    "        \n",
    "        for inner in range(len(data_list)):\n",
    "            if len(data_list[inner]) > max_batch_seq_len:\n",
    "                data_list[inner] = data_list[inner[:max_batch_seq_len]]\n",
    "            elif len(data_list[inner]) < max_batch_seq_len:\n",
    "                data_list[inner] += [0] * ( max_batch_seq_len - len(data_list[inner]))\n",
    "        \n",
    "        data_list = np.array(data_list)\n",
    "        label_list = np.array(label_list)\n",
    "        data_list = torch.from_numpy(data_list)\n",
    "        label_list = torch.from_numpy(label_list)\n",
    "        return [data_list, label_list]\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    " #Sort sequences \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "BATCH_SIZE = 64\n",
    "max_sent_length= 128\n",
    "train_dataset = SpamDataset(train_data_indices, train_labels, max_sent_length)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           collate_fn=train_dataset.spam_collate_func,\n",
    "                                           shuffle=True)\n",
    "\n",
    "val_dataset = SpamDataset(val_data_indices, val_labels, train_dataset.max_sent_length)\n",
    "val_loader = torch.utils.data.DataLoader(dataset=val_dataset, \n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           collate_fn=train_dataset.spam_collate_func,\n",
    "                                           shuffle=False)\n",
    "\n",
    "test_dataset = SpamDataset(test_data_indices, test_labels, train_dataset.max_sent_length)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           collate_fn=train_dataset.spam_collate_func,\n",
    "                                           shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XWgRGaCWf4Zz"
   },
   "source": [
    "Let's try to print out an batch from train_loader.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "executionInfo": {
     "elapsed": 357,
     "status": "ok",
     "timestamp": 1581547476149,
     "user": {
      "displayName": "Phu Mon Htut",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBI1zWVSj8KF1s1_jeDXNGym9w1t-flSjNjJ-SN=s64",
      "userId": "00211106001036927242"
     },
     "user_tz": 300
    },
    "id": "5O8R_KhwxULI",
    "outputId": "0406050e-f8b9-4c62-954a-0b6e21209d60"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data batch dimension:  torch.Size([64, 83])\n",
      "tensor([  145,    65,     1,    38,     9,   532,     5,   656,  4843,     8,\n",
      "         9579,    15,    52,    84, 13699, 38204, 13699,    79,  4390,     8,\n",
      "            1,     7,     2,  1187, 29326,    33,   647,   224,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0])\n",
      "data_batch:  tensor([[ 145,   65,    1,  ...,    0,    0,    0],\n",
      "        [ 104,   83,  916,  ...,    0,    0,    0],\n",
      "        [7959, 2127,  807,  ...,    0,    0,    0],\n",
      "        ...,\n",
      "        [ 104,   43,    1,  ...,    0,    0,    0],\n",
      "        [6481,   88,  322,  ...,    0,    0,    0],\n",
      "        [   1,   28,  868,  ...,    0,    0,    0]])\n",
      "labels:  tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0,\n",
      "        0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1,\n",
      "        0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0])\n"
     ]
    }
   ],
   "source": [
    "data_batch, labels = next(iter(train_loader))\n",
    "print(\"data batch dimension: \", data_batch.size())\n",
    "print(data_batch[0])\n",
    "print(\"data_batch: \", data_batch)\n",
    "print(\"labels: \", labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([28,  8, 11, 10, 19,  4,  8, 32,  1, 37, 42,  6, 12, 28,  7,  6,  9, 28,\n",
       "        38,  7, 42, 15, 25, 10, 19, 14, 83,  7, 29, 15, 32, 10,  9, 33, 24, 28,\n",
       "         6, 16, 21, 30,  4, 39,  5, 23, 32, 16, 17, 20, 15,  8, 25, 18, 18,  6,\n",
       "         8, 30, 21,  6, 26, 33, 14, 22, 29, 15])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking boolean and summing up correct values. \n",
    "(data_batch != 0).sum(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HpdnYbPIgNXw"
   },
   "source": [
    "## Build a BiLSTM Classifier (20 + 25 + 10 pts)\n",
    "\n",
    "Now we are going to build a BiLSTM classifier. Check this [blog post](https://colah.github.io/posts/2015-08-Understanding-LSTMs/) and [`torch.nn.LSTM`](https://pytorch.org/docs/stable/nn.html?highlight=lstm#torch.nn.LSTM) for reference.  \n",
    "\n",
    "The hyperparameters for LSTM are already given, but they are not necessarily optimal. You should get a good accuracy with these hyperparameters but you may try to tune the hyperparameters and use different hyperparameters to get better performance.\n",
    "\n",
    "* `__init__`: Class constructor. Here we define layers / parameters of LSTM.\n",
    "* `forward`: This function is used whenever you call your object as `model()`. It takes the input minibatch and returns the output representation from LSTM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "GOYEmADNDVIh"
   },
   "outputs": [],
   "source": [
    "# First import torch related libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class LSTMClassifier(nn.Module):\n",
    "    \"\"\"\n",
    "    LSTMClassifier classification model\n",
    "    \"\"\"\n",
    "    def __init__(self, embeddings, hidden_size, num_layers, num_classes, bidirectional, dropout_prob=0.3):\n",
    "        super().__init__()\n",
    "#         self.embedding_layer = self.load_pretrained_embeddings(embeddings)\n",
    "#         self.dropout = nn.Dropout(p = dropout_prob)\n",
    "#         self.lstm = nn.LSTM(self.embedding_layer.embedding_dim, hidden_size, num_layers, bidirectional=bidirectional)\n",
    "#         self.non_linearity = nn.ReLU()\n",
    "#         self.clf = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "        self.embedding_layer = self.load_pretrained_embeddings(embeddings)\n",
    "        self.dropout = nn.Dropout(p = dropout_prob)\n",
    "        self.lstm = nn.LSTM(self.embedding_layer.embedding_dim, hidden_size, num_layers, bidirectional=bidirectional, batch_first= True)\n",
    "        self.non_linearity = nn.Tanh()\n",
    "        self.clf = nn.Linear(hidden_size*2, num_classes)\n",
    "      #  self.pool = nn.AdaptiveMaxPool1d(hidden_size)\n",
    "    def load_pretrained_embeddings(self, embeddings):\n",
    "        \"\"\"\n",
    "           The code for loading embeddings from Lab 3 Deep Learning\n",
    "           Unlike lab, we are not setting `embedding_layer.weight.requires_grad = False`\n",
    "           because we want to finetune the embeddings on our data\n",
    "        \"\"\"\n",
    "        embedding_layer = nn.Embedding(embeddings.shape[0], embeddings.shape[1], padding_idx=0)\n",
    "        embedding_layer.weight.data = torch.Tensor(embeddings).float()\n",
    "        return embedding_layer\n",
    "\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        logits = None\n",
    "        #Logits are un-normalized log probabilities, THEY ARE THE RAW VALUES FOR THE SOFTMAX FUNCTION\n",
    "        \n",
    "        \"\"\"\n",
    "           Write forward pass for LSTM\n",
    "           Example, forward:= embedding -> bilstm -> pooling (sum?mean?max?) \n",
    "                              nonlinearity -> classifier\n",
    "           Refer to: https://arxiv.org/abs/1705.02364 \n",
    "           Return logits\n",
    "           You may refer to Lab 3 for embedding lookup and how to return logits\n",
    "           3. TODO: Your code here\n",
    "        \"\"\"\n",
    "        \n",
    "    \n",
    "        embedded = self.embedding_layer(inputs)\n",
    "        z1,_ = self.lstm(embedded)\n",
    "        total_sum = z1.sum(dim = 1)\n",
    "        z2 = self.non_linearity(total_sum)\n",
    "        logits = self.clf(z2)\n",
    "\n",
    "       \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p6P7O47Lfr0a"
   },
   "source": [
    "First, we will define an evaluation function that will return the accuracy of the model. We will use this to compute validation accuracy and test accuracy of the model given a dataloader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHECK THE DOCUMENTATION FOR THE LSTM EMBEDDINGS LAYER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "id": "dSkdBx1ULCFK"
   },
   "outputs": [],
   "source": [
    "def evaluate(model, dataloader, device):\n",
    "    accuracy = None\n",
    "    model.eval()\n",
    "    \"\"\"\n",
    "        4. TODO: Your code here\n",
    "        Calculate the accuracy of the model on the data in dataloader\n",
    "        You may refer to `run_inference` function from Lab 3 Deep Learning \n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "        The run inference function is: \n",
    "        def run_inference(model, dataloader, labels, device):\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                all_preds = []\n",
    "                for batch_text, batch_labels in dataloader:\n",
    "                preds = model(batch_text.to(device))\n",
    "                all_preds.append(preds.detach().cpu().numpy())\n",
    "            return np.concatenate(all_preds, axis=0)\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "        maximum, over your row. \n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        all_preds = []\n",
    "        label = []\n",
    "        for batch_text, batch_labels in dataloader:\n",
    "            preds = model(batch_text.to(device))\n",
    "            all_preds.append(preds.detach().cpu().numpy())\n",
    "            label.append(batch_labels.numpy())\n",
    "    label = np.concatenate(label)        \n",
    "    listAcc = np.concatenate(all_preds, axis=1)\n",
    "    accuracy = (label==listAcc.argmax(-1)).mean()\n",
    "    \n",
    "    return accuracy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JpCXZCO7iuEL"
   },
   "source": [
    "# Initialize the BiLSTM classifier model, criterion and optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "executionInfo": {
     "elapsed": 738,
     "status": "ok",
     "timestamp": 1581545849465,
     "user": {
      "displayName": "Phu Mon Htut",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBI1zWVSj8KF1s1_jeDXNGym9w1t-flSjNjJ-SN=s64",
      "userId": "00211106001036927242"
     },
     "user_tz": 300
    },
    "id": "YaPW_CjlK0F7",
    "outputId": "60b93196-4c04-447c-c964-46f96a61834b"
   },
   "outputs": [],
   "source": [
    "# BiLSTM hyperparameters\n",
    "\n",
    "\"\"\"\n",
    "You can change these hyperparameters to get a better accuracy. But you can get to it LATER!!!\n",
    "\"\"\"\n",
    "hidden_size = 32\n",
    "num_layers = 1\n",
    "num_classes = 2\n",
    "bidirectional= True\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "\n",
    "# if cuda exists, use cuda, else run on cpu\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "else:\n",
    "    device=torch.device('cpu')\n",
    "\n",
    "model = LSTMClassifier(embeddings, hidden_size, num_layers, num_classes, bidirectional)\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GwkHYzbQikT4"
   },
   "source": [
    "# Train model with early stopping (10 pts)\n",
    "\n",
    "Train the model for `NUM_EPOCHS`. \n",
    "Keep track of training loss.  \n",
    "Compute the validation accuracy after each epoch. Keep track of the best validation accuracy and save the model with the best validation accuracy.  \n",
    "\n",
    "If the validation accuracy does not improve for more than `early_stop_patience` number of epochs in a row, stop training. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 290,
     "referenced_widgets": [
      "ffa4694843e146bfa077ff6ac50cdb41",
      "a183c3ce4b4c45df9dce8b95ba76be91",
      "02c9fe66444f428ab4408721a83cc973",
      "03ab8514b8e14283949ffbcef2562c91",
      "a49169acbd3e43b9a3590a82e68a9c1f",
      "a4d697719c0147488eb9aa66ab63aba3",
      "b250f8be29fd48c481a9586a036041d2",
      "ad486b7ed7cf4d078113cb68c0fa40ef"
     ]
    },
    "executionInfo": {
     "elapsed": 177378,
     "status": "ok",
     "timestamp": 1581546027697,
     "user": {
      "displayName": "Phu Mon Htut",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBI1zWVSj8KF1s1_jeDXNGym9w1t-flSjNjJ-SN=s64",
      "userId": "00211106001036927242"
     },
     "user_tz": 300
    },
    "id": "QOlop_TMOD9V",
    "outputId": "a69e0251-3c4a-408a-ce89-0c2e845a6d44"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e407665ac1a45bc9cedf77048e7190d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Just a validation dataset model \n",
    "\n",
    "train_loss_history = []\n",
    "val_accuracy_history = []\n",
    "best_val_accuracy = 0\n",
    "n_no_improve = 0\n",
    "early_stop_patience=2\n",
    "NUM_EPOCHS=10\n",
    "\n",
    "val_accuracy_history.append(0)\n",
    "    \n",
    "    \n",
    "for epoch in tqdm(range(NUM_EPOCHS)):\n",
    "    model.train() # this enables regularization, which we don't currently have\n",
    "    for i, (data_batch, batch_labels) in enumerate(train_loader):\n",
    "        \"\"\"\n",
    "           Code for training lstm\n",
    "           Keep track of training of for each batch using train_loss_history\n",
    "        \"\"\"\n",
    "        preds = model(data_batch.to(device))\n",
    "        loss = criterion(preds, batch_labels.to(device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        train_loss_history.append(loss.item())\n",
    "        \n",
    "    # The end of a training epoch \n",
    "\n",
    "    \"\"\"\n",
    "        Code for tracking best validation accuracy, saving the best model, and early stopping\n",
    "        # Compute validation accuracy after each training epoch using `evaluate` function\n",
    "        # Keep track of validation accuracy in `val_accuracy_history`\n",
    "        # save model with best validation accuracy, hint: torch.save(model, 'best_model.pt')\n",
    "        # Early stopping: \n",
    "        # stop training if the validation accuracy does not improve for more than `early_stop_patience` runs\n",
    "        5. TODO: Your code here\n",
    "    \"\"\"\n",
    "#     #Calculate Accuracy\n",
    "#     accuracy = evaluate(model, train_loader, device)\n",
    "#     #Append the accuracy to the history\n",
    "#     val_accuracy_history.append(accuracy)\n",
    "#     #Best Validation Accuracy\n",
    "#     if accuracy == max(val_accuracy_history):\n",
    "#         best_val_accuracy = torch.save(model, 'best_model.pt')\n",
    "#     #Stop training logic\n",
    "#     #Get the last digits from the array - n from the early stop patience\n",
    "#     new_list = val_accuracy_history[-early_stop_patience:]\n",
    "#     value_list = []\n",
    "#     for items in new_list:\n",
    "#         if accuracy > items:\n",
    "#             value_list.append(True)\n",
    "#         else:\n",
    "#             value_list.append(False)\n",
    "            \n",
    "#     if(all(value_list) & len(value_list > 0)):\n",
    "#         pass\n",
    "    \n",
    "#     elif(any(value_list)):\n",
    "#         pass\n",
    "#     else:\n",
    "#         break\n",
    "\n",
    "    val_accuracy = evaluate(model, val_loader, device)\n",
    "    val_accuracy_history.append(val_accuracy)\n",
    "    best_val_accuracy = max(val_accuracy_history)\n",
    "    if val_accuracy == best_val_accuracy:\n",
    "        torch.save(model, 'best_model.pt')\n",
    "        n_no_improve = 0 \n",
    "        \n",
    "    elif val_accuracy < best_val_accuracy:\n",
    "        n_no_improve +=1\n",
    "        if n_no_improve == early_stop_patience:\n",
    "            break\n",
    "        \n",
    "    \n",
    "    #Before the epochs training, make sure that the dimensions in the forward functions are correct\n",
    "    #Then you have to make sure that your Evaluate Function works correctly\n",
    "    #Then run this, so you can train your epochs\n",
    "   \n",
    "\n",
    "\n",
    "print(\"Best validation accuracy is: \", best_val_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0hhFpkMHnT7Z"
   },
   "source": [
    "#Question: Why do we want to use early stopping? Write the most important reason in concise way. (10 pts)\n",
    "\n",
    "Your answer:\n",
    "\n",
    "Early stopping is used to conserve computational power by preventing unnecessary computations. Moreover, the more important reason to use early stopping is to prevent the overfitting of data. If the validation set starts to degrade, this will lead to poor performance of the model in the real world. We stop training the NN, when the performance stops improving on the validation dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I58rTeMEg05M"
   },
   "source": [
    "# Draw training curve \n",
    "X-axis: training steps, Y-axis: training loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "executionInfo": {
     "elapsed": 573,
     "status": "ok",
     "timestamp": 1581546264450,
     "user": {
      "displayName": "Phu Mon Htut",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBI1zWVSj8KF1s1_jeDXNGym9w1t-flSjNjJ-SN=s64",
      "userId": "00211106001036927242"
     },
     "user_tz": 300
    },
    "id": "KyalZo6tSXo_",
    "outputId": "58d0c42f-f8d0-4bc2-f166-1777b2f5379b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fbbd0e8f510>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(train_loss_history).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oMiI_u4ggvQK"
   },
   "source": [
    "# Validation accuracy curve\n",
    "X-axis: Epochs, Y-axis: validation accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "executionInfo": {
     "elapsed": 766,
     "status": "ok",
     "timestamp": 1581546267665,
     "user": {
      "displayName": "Phu Mon Htut",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBI1zWVSj8KF1s1_jeDXNGym9w1t-flSjNjJ-SN=s64",
      "userId": "00211106001036927242"
     },
     "user_tz": 300
    },
    "id": "Qt8iNjFwPVtc",
    "outputId": "c721506d-b96b-4488-dcf1-0b91a86fe51f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fbbd0e50650>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(val_accuracy_history).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qqanG00Ggluj"
   },
   "source": [
    "## You should expect to get test accuracy >= 95."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 884,
     "status": "ok",
     "timestamp": 1581546277092,
     "user": {
      "displayName": "Phu Mon Htut",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBI1zWVSj8KF1s1_jeDXNGym9w1t-flSjNjJ-SN=s64",
      "userId": "00211106001036927242"
     },
     "user_tz": 300
    },
    "id": "cw6KtE2uSf1X",
    "outputId": "80b32fb5-10bf-4104-c8d5-eb5f3f53e83f"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "evaluate() missing 1 required positional argument: 'device'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-404200813d49>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Compute test accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'best_model.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtest_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_accuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: evaluate() missing 1 required positional argument: 'device'"
     ]
    }
   ],
   "source": [
    "# Reload best model from saved checkpoint\n",
    "# Compute test accuracy\n",
    "model = torch.load('best_model.pt')\n",
    "test_accuracy = evaluate(model, test_loader)\n",
    "print(test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "HW2. Spam Classification with LSTM.ipynb",
   "provenance": [
    {
     "file_id": "1vJLCGEeX6JnuIm7ADEpWd7NeJSgLeuip",
     "timestamp": 1581546304452
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "00c07b0a26424be38807df93cc5c0cd2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "02c9fe66444f428ab4408721a83cc973": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a4d697719c0147488eb9aa66ab63aba3",
      "max": 10,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a49169acbd3e43b9a3590a82e68a9c1f",
      "value": 8
     }
    },
    "03ab8514b8e14283949ffbcef2562c91": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ad486b7ed7cf4d078113cb68c0fa40ef",
      "placeholder": "​",
      "style": "IPY_MODEL_b250f8be29fd48c481a9586a036041d2",
      "value": " 80% 8/10 [02:37&lt;00:39, 19.65s/it]"
     }
    },
    "070548aec28842259e1ea3a56ec5f24e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "088ecefc78274663baf410c288d239df": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "14f76745c455472da992886739bbdf1c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1681f6d76be54ca09c5894ac248ee6b6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_00c07b0a26424be38807df93cc5c0cd2",
      "placeholder": "​",
      "style": "IPY_MODEL_6c5fe2fc16544a1690da6130c349ae36",
      "value": "100% 835/835 [00:00&lt;00:00, 2529.72it/s]"
     }
    },
    "242d4868e48445c7a624a3c95f0d7710": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3b2d8b29cfde4d66a81e3bd00be18493",
       "IPY_MODEL_1681f6d76be54ca09c5894ac248ee6b6"
      ],
      "layout": "IPY_MODEL_7a19d829556d4f9198408b1f84c3526c"
     }
    },
    "2b25f1a2a08c438da35372a5c72ee41d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2f45fd22bee14ee092023d043ac17b6e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9d82ca66f33f41ca92c48e04d6d0f5e3",
      "max": 835,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_14f76745c455472da992886739bbdf1c",
      "value": 835
     }
    },
    "3b2d8b29cfde4d66a81e3bd00be18493": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7116d260b3cf48138bbf372c8d7b0cf8",
      "max": 835,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_95d22e0e4a8f4a31aa861ee389f284d2",
      "value": 835
     }
    },
    "48ac271c21f44353b5f8b0aec3b05f5b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f10d44bc20994ac085c99ea5d2383a00",
       "IPY_MODEL_6119a6e4075c4cde9bcef0773bbfa48e"
      ],
      "layout": "IPY_MODEL_070548aec28842259e1ea3a56ec5f24e"
     }
    },
    "6119a6e4075c4cde9bcef0773bbfa48e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d6dbe87216d44c1fb48e2a2896aa0a61",
      "placeholder": "​",
      "style": "IPY_MODEL_829223f1edb744309a9b77d3fa6818a3",
      "value": "100% 3902/3902 [00:01&lt;00:00, 2735.98it/s]"
     }
    },
    "6c5fe2fc16544a1690da6130c349ae36": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6f5a934da1a5478e8fc92b38c5a40584": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "7116d260b3cf48138bbf372c8d7b0cf8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "783b727fd7954625ab4c5ef7dd6d4b6a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2f45fd22bee14ee092023d043ac17b6e",
       "IPY_MODEL_d195ffd274974c2e96f5d283b2055118"
      ],
      "layout": "IPY_MODEL_cd9df6cf8cd745e7b62f5e7a53ba4ec5"
     }
    },
    "7a19d829556d4f9198408b1f84c3526c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "829223f1edb744309a9b77d3fa6818a3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "95d22e0e4a8f4a31aa861ee389f284d2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "9d82ca66f33f41ca92c48e04d6d0f5e3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a183c3ce4b4c45df9dce8b95ba76be91": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a49169acbd3e43b9a3590a82e68a9c1f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a4d697719c0147488eb9aa66ab63aba3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ad486b7ed7cf4d078113cb68c0fa40ef": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b250f8be29fd48c481a9586a036041d2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cd9df6cf8cd745e7b62f5e7a53ba4ec5": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d195ffd274974c2e96f5d283b2055118": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_088ecefc78274663baf410c288d239df",
      "placeholder": "​",
      "style": "IPY_MODEL_d3e79f8c059444539bf1d0436402ff12",
      "value": "100% 835/835 [00:00&lt;00:00, 2686.11it/s]"
     }
    },
    "d3e79f8c059444539bf1d0436402ff12": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d6dbe87216d44c1fb48e2a2896aa0a61": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f10d44bc20994ac085c99ea5d2383a00": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2b25f1a2a08c438da35372a5c72ee41d",
      "max": 3902,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6f5a934da1a5478e8fc92b38c5a40584",
      "value": 3902
     }
    },
    "ffa4694843e146bfa077ff6ac50cdb41": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_02c9fe66444f428ab4408721a83cc973",
       "IPY_MODEL_03ab8514b8e14283949ffbcef2562c91"
      ],
      "layout": "IPY_MODEL_a183c3ce4b4c45df9dce8b95ba76be91"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
